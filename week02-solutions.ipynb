{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practical 1#\n",
    "\n",
    "In this practical you will solve a number of linear regression problems using both linear algebra based approaches and machine learning models. Linear regression model can be represented as the following equation:\n",
    "$$\n",
    "y=\\beta_0 + \\beta_1x_1 + \\dots +\\beta_kx_k\n",
    "$$\n",
    "\n",
    "where $x_i$ are the features of $x$, $y$ represent class label of $x$ and $\\beta_0 \\dots \\beta_k$ are the parameters of the model. Solving linear regression model means finding the values of the parameters using training dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1##\n",
    "\n",
    "We will start with solving a simple regression problem using linear algebra."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**T1.1 Run the cell below to generate your input/output data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# input values from 0 to 30\n",
    "inputs = 30 * np.random.random((20, 1))\n",
    "# output = a*input + b with noise\n",
    "outputs = 0.5 * inputs + 1.0 + np.random.normal(size=inputs.shape)\n",
    "#plt.plot(inputs,outputs,'ro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "**T1.2 Including bias** \n",
    "\n",
    "In order to represent the linear regression equation in matrix notation we need to add vector of ones to our input data. This can be done by creating a column of ones and concatenating ([numpy.concatenate](https://docs.scipy.org/doc/numpy/reference/generated/numpy.concatenate.html)) it with your input data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding bias\n",
    "bias = np.ones([len(inputs),1])\n",
    "x_bias = np.concatenate((bias, inputs), 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "**T1.3 Finding parameters (coefficients) of the regression models**\n",
    "\n",
    "Using linear algebra and the generated data, find the coefficients $\\beta=(\\beta_0, \\beta_1)$ by solving the equation from the lecture: $\\beta=(X^TX)^{-1}X^TY$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.15276162]\n",
      " [0.56123959]]\n"
     ]
    }
   ],
   "source": [
    "from numpy import linalg as LA\n",
    "#calculate regression coefficients without regularisation\n",
    "coef = LA.inv(np.transpose(x_bias)@x_bias)@np.transpose(x_bias)@outputs\n",
    "print(coef)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "**T1.4. Visualizing the model**\n",
    "\n",
    "Plot the graph of the linear model (line: $y=\\beta_0+\\beta_1x_1$) together with the raw data points (inputs/outputs) using [matplotlib](https://matplotlib.org/tutorials/introductory/pyplot.html) in order to see how well the model fits the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x22d6a132d68>]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXsAAAD8CAYAAACW/ATfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAHVpJREFUeJzt3Xl8VPW9//HXBxAlgAuLimgyaFHqVoVURa8XFEVW6a+3Czb1orZN7WJtrb0G41qMYqu21lp7c61VbK61P5fWnygFF8QNNFApCFpZAqIIgsqqLOH7++NMQs5kJpnMds7MvJ+PB4/J+c6ZmQ8nk3e++Z7vfI855xARkcLWKegCREQk+xT2IiJFQGEvIlIEFPYiIkVAYS8iUgQU9iIiRUBhLyJSBBT2IiJFQGEvIlIEuuTyxfr06eMikUguX1JEJO/Nnz9/g3OubzrPkdOwj0Qi1NfX5/IlRUTynpmtSvc5NIwjIlIEFPYiIkVAYS8iUgQU9iIiRUBhLyJSBBT2IlJ86uogEoFOnbzburqgK8q6nE69FBEJXF0dVFbC9u3e9qpV3jZARUVwdWWZevYiUlyqq/cGfZPt2732AqawF5Hisnp1x9oLhMJeRIpLaWnH2guEwl5EiktNDZSU+NtKSrz2AqawF5HiUlEBtbVQVgZm3m1tbUGfnAXNxhGRYlRRUfDhHks9exGRIqCwFxHJorWbPuXBuato3OMCrUPDOCIiWeCco/LB+cxasg6A4Uf35YheJe08KnvaDXszuw8YB6x3zh0fbfslMB7YCSwHLnbOfZLNQkVE8sWsJev4zrS9F2qaMuG4QIMekuvZ3w/8FpjWom0WMNk5t9vMbgUmA1dlvjwRkfzx8badnDxlVvP20Yf04MnLzqRrl+BHzNsNe+fcHDOLxLTNbLE5F/hKZssSEckvkx9bxEOv7f0U7tOXn8nn++0fYEV+mRizvwR4ONGdZlYJVAKUFvgn1ESk+MxdsZGJtXObt68492h+NGJggBXFl1bYm1k1sBtIuD6oc64WqAUoLy8P9nS0iEiGbNuxm1NvfpatO3YD0Lt7V1666my6de0ccGXxpRz2ZjYJ78TtCOecQlxEisbtM9/mrueWNW8/culQyiO9AqyofSmdNTCzUXgnZM93zm1vb38RkUKw+L1NRKqmNwf9pKFlNEwd23bQh+RCKclMvXwIGA70MbM1wPV4s2/2BWaZGcBc59ylWaxTRCQwO3Y3ct6v5tCwcW/fduF1IzmgZJ+2HxiiC6VYLkdgysvLXX19ffs7ioiExH0vreTnTy5p3v7jRV/krEEHJ/fgSMQL+FhlZdDQkHQNZjbfOVee9APi0CdoRUTiWLlhG2fdNrt5e+yJ/fjtBScTHc1ITogulKKwFxFpoXGP4+v//Sr1qz5ubnvt6hEcvP9+HX+y0tL4PfsApqEH/7EuESlcITk5mazH/7GGo65+qjno75x4Eg1Tx6YW9BCqC6WoZy8i2RGik5PtWbf5M069+dnm7VMH9OJ/v3ManTt1YMgmnqb/Z3W1N3RTWuoFfQD/f52gFZHsyNDJyWxyzvH9ugU8vfiD5rbZVw4n0qd7gFW1phO0IhJeITo5Gc91f1vMtFf3/jK6YfyxXHTGgAAryi6FvYhkR4hOTra0auM2hv1ydvP24Qd147mfDg/FypTZpLAXkeyoqfGP2UNgJyebRKqm+7Zv/+oX+I8hhwdUTW4V9q8yEQlORQXU1npj9GbebW1taicn05zVc8/s5a2CvmHq2KIJelDPXkSyqaIi/Zknaczq2bh1B0NuesbX9nr1OfTtuW96NeUhzcYRkXBLcVbPkZOn0/Ia3z877xh+cNbnMl5eLmg2jogUvg7O6nn8H2v4ycMLfW0NU8dmuqq8o7AXkXBLclbP9p27Ofa6v/vanr9yOANCNmc+KAp7EQm3JGb1nHvHC7yzfmvz9gWnlHLLl0/IZZWhp7AXkXBrY8mBF9/5kAv/8Jpv9xU3j6FTusscFCCFvYiEX8ysnt2Ne/hczFTKv/7gDE464sBcV5Y3FPYikle+/UA9zyxd17x95sA+PPitUwOsKD8o7EUkLyx+bxPj7nrJ1/avm0YX/DIHmaKwF5FQc84xYPJTvrb7Lirn7EGHBFRRflLYi0honX3bbFZs2Na83W2fziydMirAivKXwl5EQifekM2Ca8+lV/euAVWU/xT2IhIqsQuWTRpaxo0Tjg+omsKhsBeRULj0wfnMePMDX5uWOcgchb2IBOr9Tz7l9KnP+drCeGnAfNdu2JvZfcA4YL1z7vhoWy/gYSACNABfc859nL0yRaQQxQ7ZDD2yNw9VnhZQNYUtmQmq9wOxp7+rgGedcwOBZ6PbIiJJ+cWMt+JeTERBnz3t9uydc3PMLBLTPAEYHv36AWA2cFUG6xKRArT5s12ceMNMX9uj3xvKkLJeAVVUPFIdsz/EObcWwDm31swOzmBNIlKAYnvyvbp3ZcG15wZUTfHJ+glaM6sEKgFKA76qvIjk3sOvr+aqRxf52pbfPIbOWpkyp1IN+3Vm1i/aq+8HrE+0o3OuFqgF77KEKb6eiOSZXY17GFj9tK/t7m8MZuyJ/QKqqLilGvZPAJOAqdHbv2WsIhHJe7FDNqA580FLZurlQ3gnY/uY2RrgeryQ/4uZfQtYDXw1m0WKSH6Y868P+c/7/BcTWfrzUXTr2jmgiqRJMrNxLkhw14gM1yIieSreypSTRw/iu8OOCqgiiaVP0IpIWkb9eg5vfbDF16Yhm/BR2ItISpau3czoO1/0tdVfcw59euwbUEXSFoW9iHRY7AnYC045glu+fGJA1UgyFPYikrQzf/Ec7370qa9NQzb5QWEvIu1q2LCN4bfN9rU9+9NhHNW3RzAFSYcp7EWkTZozXxgU9iIS1/fr5vPUIv/FRFbeMgYzLXOQjxT2IuKzafsuvvBz/8qU91QMZvQJWuYgnynsRaSZhmwKl8JeRPivRxbyl/o1vrZlNaPp0jmZ6xtJPlDYixSxHbsbOeaaGb62SUPLuHHC8QFVJNmisBcpUhqyKS76G02kyNz/8spWQf+Pa89NLujr6iASgU6dvNu6uqzUKJmnnr1IkYi3MuWJhx/AEz/8t/YfXFcHl18OGzfubVu1Ciorva8rKjJYqWSDwl6kCKQ1ZFNX54X69u2t79u+HaqrFfZ5QGEvUsDiXUzkmSuG8bmDO7DMQXV1/KBvsnp1itVJLinsRQpUxk7AthfmpaUdf07JOYW9SIHJ+Cyb0lJvfD6ekhKoqUn9uSVnNBtHpEAsW7+lVdBPu+SU9KdT1tR4oR6rd2+ordV4fZ5Qz16kAGR1znxTmFdXe0M6paXeLwCFfF5R2IvksfF3vcSi9zb52rKyMmVFhcI9zynsRfLQx9t2cvKUWb62G8Yfy0VnDAioIgk7hb1IntEyB5IKhb1Inrj2r4t5cK5/VszbN41i3y6dA6pI8olm44iE3K7GPUSqpvuC/mvlh9MwdWxmg17r3hS0tHr2ZvYT4NuAAxYBFzvnPstEYSKSwyGb2CURtO5NwUm5Z29m/YEfAeXOueOBzsDETBUmUszq5q1qFfT115yTvbH5eEsiNK17IwUh3TH7LkA3M9sFlADvp1+SSPGKtzLl0Yf0YOZPhmX3hRMtiaB1bwpGymHvnHvPzG4DVgOfAjOdczNj9zOzSqASoFRraIgkFOgsm0RLIuhntmCkM4xzEDABGAAcBnQ3s2/G7uecq3XOlTvnyvv27Zt6pSIF6pVlG1oF/Ywfn5nb6ZTxlkTQujcFJZ3ZOOcAK51zHzrndgGPAadnpiyRkMrwjJVI1XS+ce88X1vD1LEMOnT/tJ63wyoqvHVuysrAzLvVujcFJZ0x+9XAaWZWgjeMMwKoz0hVImGUwRkrofxglJZEKGgp9+ydc/OAR4AFeNMuOwG1GapLJHwyMGNl5YZtrYL+D5PKgw96KXhpzcZxzl0PXJ+hWkTCLc0ZK6HszUvR0HIJIslKccbKV3//Cq83fOxry8rKlCJt0HIJIsnq4IyVTZ/uIlI13Rf0V48ZRMPUsQp6yTn17EWS1YGLeGjIRsJGYS/SEe3MWPlB3QKmL1rra3tryij220crU0qwFPYiGbCrcQ8Dq5/2tQ0pO4hHv6ePnkg4KOxF0qQhG8kHCnuRFNXOWc7NT73la3ul6mwOO7BbQBWJJKawF0mBevOSbxT2Ih2gkJd8pbAXScLLyzZQEbNg2SOXDqU80iugikQ6RmEv0g715qUQ6BO0IglEqqa3CvqGqWOTC3pdvFtCRj17kRgNG7Yx/LbZvrY7J57EhJP6J/cEuni3hJA553L2YuXl5a6+XkveS3hlZMgmEom/YFpZGTQ0pFSXFDczm++cK0/nOdSzFwHG3fUii9/b7GtbcfMYOnVKYcEyXbxbQkhj9lJcYsbSN0+rI1I13Rf0lw47ioapY1MLeki85LEu3i0BUthL8WgaS1+1CpwjMvFuTlxyoG+XhqljqRo9qO3naO/Eqy7eLSGkYRwpHtHLCl5/znd5YMh4311Lfn4eJV3b+XFI9sRrB5ZCFskVnaCVwlBX1264NnbuwlE/+5uvbeiqhTz08DWwZ0/7r6ETrxIQnaAVgaR63JGq6RAT9A23jvO+KCtL7nV04lXymMJe8l90eMZn+3aorubPA8+k6rFFvrte/t3F9N/yobfRkbH0FK9BKxIGOkEr+S9Bzzoy8e5WQd9wwif071UCZl6PvrY2+bF0nXiVPKaeveS/mB535KonW+3i+2BUqidKdeJV8phO0Er+i47ZL+rZj/EX3em769HvDWVImVamlPwW+AlaMzsQuBc4HnDAJc65V9N5TpEOq6ggsujAVs1amVJkr3SHce4EZjjnvmJmXYGS9h4gkknn3vEC76zf6mtTyIu0lnLYm9n+wL8DFwE453YCOzNTlkjb1m3+jFNvftbXVnvhEEYed2hAFYmEWzo9+yOBD4E/mtkXgPnA5c65bRmpTCQBXUxEpOPSCfsuwGDgMufcPDO7E6gCrm25k5lVApUApZqPLGn46V8W8uiCNb62lFemFCky6YT9GmCNc67pwpyP4IW9j3OuFqgFbzZOGq8nRerTnY18/roZvrbJowfx3WFHBVSRSP5JOeydcx+Y2btmdoxz7m1gBLAkc6WJaMhGJFPSnY1zGVAXnYmzArg4/ZJE4N4XV3DT9KW+tqRWphSRuNL6yXHOvQGkNdFfpKU9exxHXv2Ur+3LJ/fnjq+fFFBFIoVB3SQJDQ3ZiGSPwl4C98ySdXx7mn8ZjVcnn02/A7oFVJFI4VHYS6Bie/NH9u3Ocz8dHkwxIgVMYS+B0JCNSG4p7CWnlry/mTG/edHX9sQPz+DEw1svZCYimaOwl5xRb14kOAp7ybrxd73Eovc2+doU8iK5pcsShkldHUQi0KmTd1tXF3RFaVm/5TMiVdN9Qf+7isEKepEAqGcfFtGrLTVfOHvVKm8b8vKydxqyEQkXXZYwLCIR33VUm5WVQUNDrqtJ2dWPL+J/5/kvAL785jF01sqUIinLxGUJNYwTFqtXd6w9ZD7b1Uikarov6K8ceTQNJ3xC5yMHFMzQlEi+0jBOWJSWxu/Z58E1ABIO2RTY0JRIPlPPPixqaqAk5hK+JSVee0jd//LKVkG/+Mbz9o7NV1fvDfom27d77SKSU+rZh0VTT7e62hu6KS31gj6EPWDnHAMm+1emHHtCP+6uGOzfMc+HpkQKicI+TCoqQhnuLXVolk0eD02JFBoN40hSZr+9vlXQv3TVWW1Pp8zDoSmRQqWevbQrNuT7H9iNl6vObv+BeTQ0JVLoFPaSUEY+GJUHQ1MixUBhL638a90WRv5qjq/tse+fzuDSgwKqSETSpbAXHy1zIFKYFPYCwH/c8wrzV33sa1PIixQOhX2R27h1B0NuesbXdufEk5hwUv+AKhKRbFDYFzEN2YgUD4V9EbrhiTe5/5UGX9uymtF06ayPXYgUKoV9Edmxu5Fjrpnha/vR2Z/jipHHBFSRiORK2mFvZp2BeuA959y49EuSbNCQjUhxy0TP/nJgKbB/Bp5LMqxu3iqqH1/sa/vnDSPZf799AqpIRIKQVtib2eHAWKAGuCIjFUlGxFuZ8pzPH8y9k74YUEUiEqR0e/a/Bv4L6JloBzOrBCoBSrXaYU5oyEZEYqU8/cLMxgHrnXPz29rPOVfrnCt3zpX37ds31ZeTJLy8bEOroJ/zs3ZWphSRopBOz/4M4HwzGwPsB+xvZn9yzn0zM6VJR8SGfO/uXZl/7bkBVSMiYZNy2DvnJgOTAcxsOHClgj73jrnmaXbs3uNrU09eRGJpnn2eWvHhVs6+/QVf21++O5RTBvQKqCIRCbOMhL1zbjYwOxPPJe3TCVgR6Sh9Pj4ZdXUQiUCnTt5tXV0gNVRcdHuroF95yxgFvYi0S2Hfnro6qKz0LpztnHdbWZnTwN8yrY7IogN5+dBBzW23zbqbhhM+wcxyVoeI5C9zzuXsxcrLy119fX3OXi8jIhEv4GOVlUFDQ/ZfPt6Qza3jclqDiATLzOY758rTeQ6doG3P6tUda8+QB15p4Pon3vS1LfvF+XRxLWbeZLkGESkcCvv2lJbG79ln6dPAuxr3MLD6aV/blPo/c+Gzf8pZDSJSeDRm356aGigp8beVlHjtGTb6zhdbBX3D1LFcePGonNUgIoVJPfv2VFR4t9XV3rBJaakXsk3tGfDGu5/wpbtf9rUtumEkPZtWpsxBDSJS2HSCNkDxVqa86UvH883TygKqSETCSCdo89hlD/2D/7fwfV+b5suLSLYo7HNs1cZtDPvlbF/b/GvOoXePfYMpSESKgsI+h2LnzF867CiqRg9KsLeISOYo7HPgtr+/zW+fX+Zr05CNiOSSwj6LPtq2k8FTZvnanr9yOAP6dA+oIhEpVgr7LIkdshlzwqH8rmJIQNWISLFT2GfYQ6+tZvJji3xtK28ZowXLRCRQCvsM+WxXI4OuneFre+z7pzO49KCAKhIR2UvLJWTAsdfN8AX90Yf0oGHq2PwJ+jCs1y8iWaWefRqef2s9F9//uq9tWc1ounTOo9+hTev1b9/ubTet1w9ajkGkgGi5hBQ07nEcdbV/mYP/vnAI5x13aEAVpSHg9fpFpH1aLiEAE+5+mYXvfuJry+s58wGt1y8iuaWwT9Li9zYx7q6XfG1v3nge3ffN80OY4/X6RSQYeZ5UuXFKzTOs37KjefuG8cdy0RkDAqwog2pq/GP2oLXyRQqQwr4NryzfwDf+Z56vLa+HbOLRWvkiRaGwwr6uLiOhtXXHbr540zN8uqsRgD49uvL8lcP3Xkyk0FRUKNxFClzKYW9mRwDTgEOBPUCtc+7OTBXWYRmaQnjrjLe4Z/by5m19MEpECkHKUy/NrB/Qzzm3wMx6AvOBLznnliR6TFanXqY5hXDRmk2M/+3eE7AXnxHh+vHHZa4+EZEUBTr10jm3Flgb/XqLmS0F+gMJwz6rUpxCuGN3I+fc8QLvfvQpAGbwxnUjOaBbgQ7ZiEhRysiYvZlFgJOBeW3vmUUpTCG898UV3DR9afP2A5ecwrCj+2ajOhGRQKUd9mbWA3gU+LFzbnOc+yuBSoDSbM7d7sAUwuUfbmXE7S80b0846TB+/fWTtDKliBSstMLezPbBC/o659xj8fZxztUCteCN2afzem1KYgrh7sY9fOX3r/JGi0/AvlY9goN77pe1skREwiCd2TgG/AFY6py7I3MlpaGNKYSPzF/Dlf93YfP2by44mfO/cFiuKhMRCVQ6PfszgAuBRWb2RrTtaufcU208JufWbvqUobc817x9+lG9+dO3TqVTJw3ZiEjxSGc2zktAaBPTOUflg/OZtWRdc9ucn51Fae+SAKsSEQlGYX2CNmrWknV8Z9re+fxTJhzHhUMjwRUkIhKwggr7j7ft5OQps5q3jz6kB09ediZdu+TRxURERLKgYFJw8mOLfEH/9OVnMvMnw9IPel2yT0QKQN737Oeu2MjE2rnN21ecezQ/GjEwM0+uS/aJSIHI28sSbtuxm1NvfpatO3YD0Lt7V1666my6de2ckecHdMk+EQmFor0s4e0z3+au55Y1bz9y6VDKI70y/0K6ZJ+IFIi8CvvYSwNOGlrGjROOz94L6pJ9IlIg8iLsd+xuZOSv5rBq4951bxZeN5IDSrK8MqUu2SciBSIvwv7eF1c2B/0fL/oiZw06ODcvrEv2iUiByIsTtB9u2cHcFRsZd2I/rUwpIkWnaE7Q9u25L+O1aJmISMrC/6EqfahJRCRt4e7Z60NNIiIZEe6efXW1fyYMeNvV1cHUIyKSp8Id9vpQk4hIRoQ77BN9eEkfahIR6ZBwh31Njfchppb0oSYRkQ4Ld9hXVEBtrbfwmJl3W1urk7MiIh0U7tk40OZFxEVEJDnh7tmLiEhGKOxFRIqAwl5EpAgo7EVEioDCXkSkCOR0iWMz+xCIc+mnjOoDbMjya6RKtXVcWOsC1ZaKsNYF4a7tGOdcz3SeIKdTL51zfbP9GmZWn+66z9mi2jourHWBaktFWOuC8NeW7nNoGEdEpAgo7EVEikAhhn1t0AW0QbV1XFjrAtWWirDWBQVeW05P0IqISDAKsWcvIiIx8jLszewIM3vezJaa2ZtmdnmcfYab2SYzeyP677oc1tdgZouir9vqLLp5fmNmy8zsn2Y2OAc1HdPiWLxhZpvN7Mcx++TsmJnZfWa23swWt2jrZWazzOyd6O1BCR47KbrPO2Y2KUe1/dLM3op+vx43swMTPLbN732WarvBzN5r8X0bk+Cxo8zs7ej7rioHdT3coqYGM3sjwWOzfczi5kXQ77c26srOe805l3f/gH7A4OjXPYF/AcfG7DMceDKg+hqAPm3cPwZ4GjDgNGBejuvrDHwAlAV1zIB/BwYDi1u0/QKoin5dBdwa53G9gBXR24OiXx+Ug9pGAl2iX98ar7ZkvvdZqu0G4MokvufLgSOBrsDC2J+ZTNcVc//twHUBHbO4eRH0+62NurLyXsvLnr1zbq1zbkH06y3AUqB/sFV1yARgmvPMBQ40s345fP0RwHLnXLY/4JaQc24O8FFM8wTggejXDwBfivPQ84BZzrmPnHMfA7OAUdmuzTk30zm3O7o5Fzg8k6+ZrATHLRmnAMuccyucczuBP+Md76zXZWYGfA14KFOv1xFt5EWg77dEdWXrvZaXYd+SmUWAk4F5ce4eamYLzexpMzsuh2U5YKaZzTezyjj39wfebbG9htz+sppI4h+8oI4ZwCHOubXg/SAAB8fZJ+hjB3AJ3l9m8bT3vc+WH0b/7L8vwXBEkMftTGCdc+6dBPfn7JjF5EVo3m9t5FjG3mvhv3hJG8ysB/Ao8GPn3OaYuxfgDVNsjY5h/hUYmKPSznDOvW9mBwOzzOytaM+nicV5TE6mRZlZV+B8YHKcu4M8ZskK7NgBmFk1sBuoS7BLe9/7bLgHmIJ3HKbgDZlcErNPkMftAtru1efkmMXmhfcHR/sPi9OW0eOWKMcy/V7L2569me2Dd4DqnHOPxd7vnNvsnNsa/fopYB8z65OL2pxz70dv1wOP4/0J3dIa4IgW24cD7+eiNmA0sMA5ty72jiCPWdS6puGs6O36OPsEduyiJ+fGARUuOmgaK4nvfcY559Y55xqdc3uA/0nwmoEcNzPrAnwZeDjRPrk4ZgnyIvD3W6Icy8Z7LS/DPjoG+AdgqXPujgT7HBrdDzM7Be//ujEHtXU3s55NX+OdbFkcs9sTwH+a5zRgU9OfkzmQsJcV1DFr4QmgabbDJOBvcfb5OzDSzA6KDleMjLZllZmNAq4CznfObU+wTzLf+2zU1vJ8z/9J8JqvAwPNbED0r7uJeMc7284B3nLOrYl3Zy6OWRt5Eej7LVFdWXuvZeKscq7/Af+G96fUP4E3ov/GAJcCl0b3+SHwJt6sg7nA6Tmq7cjoay6Mvn51tL1lbQbcjTc7YhFQnqPaSvDC+4AWbYEcM7xfOGuBXXi9p28BvYFngXeit72i+5YD97Z47CXAsui/i3NU2zK8sdum99vvo/seBjzV1vc+B7U9GH0f/RMvwPrF1hbdHoM342N5pmuLV1e0/f6m91eLfXN9zBLlRaDvtzbqysp7TZ+gFREpAnk5jCMiIh2jsBcRKQIKexGRIqCwFxEpAgp7EZEioLAXESkCCnsRkSKgsBcRKQL/H0OLFAgHrJmkAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(inputs,outputs,'ro')\n",
    "plt.plot(inputs,coef[0]+coef[1]*inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "**T1.4 Finding coefficient of Ridge regression model**\n",
    "\n",
    "Using linear algebra and the generated data, find coefficients of a Ridge regression model. Ridge model is obtained by adding regularizer to the loss function of the linear regression model. The coefficients of the model can be found with the following formula: $\\beta=(X^TX + \\lambda I)^{-1}X^TY$. We can set $\\lambda = 0.5.$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.14083432],\n",
       "       [0.56198012]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calculate regression coefficients with regularisation\n",
    "coef_r = LA.inv(x_bias.T@x_bias + 0.5*np.eye((x_bias.T).shape[0]))@x_bias.T@outputs\n",
    "coef_r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "**T1.5 Visualizing th model**\n",
    "\n",
    "As previously, use matplotlib to see how well the model fits the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x22d699f9b70>]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(inputs,outputs,'ro')\n",
    "plt.plot(inputs,coef_r[0]+coef_r[1]*inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2\n",
    "\n",
    "In this task you will build linear and ridge regression models for predicting wine quality. You will use linear algebra based approach and also models from scikit-learn library for comparison."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "**T2.1 Loading dataset with Pandas**\n",
    "\n",
    "In this task we use pandas library to read data from a csv file. Familiarize yourself with the wine quality dataset presented below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#reading data with panda\n",
    "df = pd.read_csv('winequality.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.9970</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            7.4              0.70         0.00             1.9      0.076   \n",
       "1            7.8              0.88         0.00             2.6      0.098   \n",
       "2            7.8              0.76         0.04             2.3      0.092   \n",
       "3           11.2              0.28         0.56             1.9      0.075   \n",
       "4            7.4              0.70         0.00             1.9      0.076   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
       "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
       "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
       "4                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "\n",
       "   alcohol  quality  \n",
       "0      9.4        5  \n",
       "1      9.8        5  \n",
       "2      9.8        5  \n",
       "3      9.8        6  \n",
       "4      9.4        5  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1599, 12)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "**T2.2 Extracting input and output variables**\n",
    "\n",
    "The first 11 features are the input variables and the last feature ('quality') is the output variable. You will have to extract the required values using appropriate methods from Pandas library. As in Task one, you should store your input and output variables in two separate matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select input and output variables\n",
    "inputs=df.values[:,:-1]\n",
    "outputs=df.values[:,11]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check whether the data was extracted correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1599, 11)\n",
      "[[ 7.4    0.7    0.    ...  3.51   0.56   9.4  ]\n",
      " [ 7.8    0.88   0.    ...  3.2    0.68   9.8  ]\n",
      " [ 7.8    0.76   0.04  ...  3.26   0.65   9.8  ]\n",
      " ...\n",
      " [ 6.3    0.51   0.13  ...  3.42   0.75  11.   ]\n",
      " [ 5.9    0.645  0.12  ...  3.57   0.71  10.2  ]\n",
      " [ 6.     0.31   0.47  ...  3.39   0.66  11.   ]]\n"
     ]
    }
   ],
   "source": [
    "print(inputs.shape)\n",
    "print(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1599,)\n",
      "[5. 5. 5. ... 6. 5. 6.]\n"
     ]
    }
   ],
   "source": [
    "print(outputs.shape)\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "**T2.3 Splitting data into training and testing set**\n",
    "\n",
    "Split the inputs and outputs data into training and testing set (50% for testing and 50% for training). You can do this manually (i.e. by splitting each matrix in half) or using [train_test_split](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) from `sklearn.model_selection` (refer to the lecture)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(799,)\n",
      "(799, 11)\n",
      "(800,)\n",
      "(800, 11)\n"
     ]
    }
   ],
   "source": [
    "#split the dataset into training and testing sample\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(inputs, outputs,test_size=0.5, random_state=0)\n",
    "print(y_train.shape)\n",
    "print(x_train.shape)\n",
    "print(y_test.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "**T2.3 Including bias**\n",
    "\n",
    "As previously, modify the input data so that we can use matrix notation to solve the linear regression problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add bias to the input variables\n",
    "x_train_bias = np.concatenate((np.ones([x_train.shape[0],1]), x_train), 1)\n",
    "x_test_bias = np.concatenate((np.ones([x_test.shape[0],1]), x_test), 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "**T2.5 Finding parameters (coefficients) of the regression models**\n",
    "\n",
    "Using linear algebra and the training data (as in Task 1) find coefficients of the linear regression models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using linear algebra to solve linear regression task on the training dataset (i.e. find the coefficients)\n",
    "B=LA.inv(np.transpose(x_train_bias)@x_train_bias)@np.transpose(x_train_bias)@y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "**T2.6 Predicting output values for instances from the testing set**\n",
    "\n",
    "Use the obtained regression model to predict output values for the instances from the testing dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use the coefficients to predict the output values for the instances from the testig dataset\n",
    "y_pred = B@np.transpose(x_test_bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "**T2.6 Evaluating the linear regression model**\n",
    "\n",
    "Evaluate how well the model did by calculating the mean and the mean square error using the ground truth values. You can use metrics from [sklearn library](http://scikit-learn.org/stable/modules/model_evaluation.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 0.5073001307579691\n",
      "Mean Squared Error: 0.4281774662475391\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "#Using the ground truth output values, calculate the mean absolute error and the mean square error \n",
    "print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))\n",
    "print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "**T2.7 Training linear regression model using scikit-learn library**\n",
    "\n",
    "Now, for comparison, create and evaluate linear regression model using [scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html) library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.38293312e-02, -1.12621647e+00,  4.96176394e-02,  4.25597209e-02,\n",
       "       -2.38529567e+00,  3.35060344e-04, -2.94653991e-03, -3.76079469e+01,\n",
       "       -4.28282642e-01,  9.74208681e-01,  2.52478567e-01])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "#comparison with linear regression from sklearn. We don't need to add bias in here\n",
    "reg = LinearRegression() \n",
    "reg.fit(x_train,y_train)\n",
    "reg.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_pred=reg.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 0.5073001301029523\n",
      "Mean Squared Error: 0.4281774656807189\n"
     ]
    }
   ],
   "source": [
    "print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, reg_pred))\n",
    "print('Mean Squared Error:', metrics.mean_squared_error(y_test, reg_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "**T2.8 Finding parameters of Ridge regression model**\n",
    "\n",
    "Now repeat the same procedure but instead of the standard linear regression model, use ridge regression model.\n",
    "\n",
    "- Use linear algebra to create the model on training data (`alpha=.5`)\n",
    "- Evaluate the model on testing data\n",
    "- Use [scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html) library to create the model on training data\n",
    "- Evaluate the model on testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4.20007706e+01,  1.38293312e-02, -1.12621647e+00,  4.96176394e-02,\n",
       "        4.25597209e-02, -2.38529567e+00,  3.35060344e-04, -2.94653991e-03,\n",
       "       -3.76079469e+01, -4.28282642e-01,  9.74208682e-01,  2.52478567e-01])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Do the same but with ridge regression\n",
    "#Using linear algebra, lambda = 0.5\n",
    "Br=LA.inv(np.transpose(x_train_bias)@x_train_bias+ 0.5*np.eye(np.transpose(x_train_bias).shape[0]))@np.transpose(x_train_bias)@y_train\n",
    "B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12,)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Br.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = x_test_bias@Br"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 0.5071001439484627\n",
      "Mean Squared Error: 0.42534323490571774\n"
     ]
    }
   ],
   "source": [
    "print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))\n",
    "print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ridge(alpha=0.5, copy_X=True, fit_intercept=True, max_iter=None,\n",
       "      normalize=False, random_state=None, solver='auto', tol=0.001)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "#Using ridgre regression model\n",
    "ridge = Ridge(alpha=.5)\n",
    "ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.24268126e-02, -1.18393832e+00,  4.51053693e-03,  2.56568453e-02,\n",
       "       -1.82960148e+00,  4.80042553e-04, -2.85097156e-03, -3.96634473e-02,\n",
       "       -5.33826740e-01,  8.34771153e-01,  2.94018369e-01])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge.fit(x_train,y_train)\n",
    "ridge.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_pred = ridge.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 0.5078012213195049\n",
      "Mean Squared Error: 0.4256691793139733\n"
     ]
    }
   ],
   "source": [
    "print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, ridge_pred))\n",
    "print('Mean Squared Error:', metrics.mean_squared_error(y_test, ridge_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3\n",
    "\n",
    "In this task we will evaluate the Ridge regression model using cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "**T3.1 Using `cross_val_score` from [sklearn.model_selection](https://scikit-learn.org/stable/modules/cross_validation.html)** \n",
    "\n",
    "Use cross_val_score to perform 5-cross-validation for the ridge model with mean absolute error as the scoring function. Remember that this should be performed on the original input/output data. We don't need to split the data into training and testing sets. Average the results obtain for all 5 folds to obtain the final score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "scores = cross_val_score(ridge, inputs, outputs, cv=5, scoring='neg_mean_absolute_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.5224996 , -0.52466074, -0.50037311, -0.50701293, -0.49740956])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.510391189258218"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "**T3.2 Useing `KFold` from [sklearn.model_selection](https://scikit-learn.org/stable/modules/cross_validation.html)**\n",
    "\n",
    "Use KFold to perform 5-cross-validation. Train and evaluate the Ridge model with each fold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 0.522499601137463\n",
      "Mean Absolute Error: 0.5246607414418176\n",
      "Mean Absolute Error: 0.5003731123381701\n",
      "Mean Absolute Error: 0.5070129348368924\n",
      "Mean Absolute Error: 0.49740955653674696\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(n_splits=5)\n",
    "for train_index, test_index in kf.split(inputs):\n",
    "    ridge.fit(inputs[train_index],outputs[train_index])\n",
    "    scores=ridge.predict(inputs[test_index])\n",
    "    print('Mean Absolute Error:', metrics.mean_absolute_error(outputs[test_index], scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "**T3.3 Useing `ShuffleSplit` from [sklearn.model_selection](https://scikit-learn.org/stable/modules/cross_validation.html)** \n",
    "\n",
    "Use `ShuffleSplit` instead of `KFold`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Mean Absolute Error: 0.48588525833445767\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "ss = ShuffleSplit(n_splits=5, test_size=0.25, random_state=0)\n",
    "score = 0\n",
    "for train_index, test_index in ss.split(inputs):\n",
    "    ridge.fit(inputs[train_index],outputs[train_index])\n",
    "    scores=ridge.predict(inputs[test_index])\n",
    "    score = score + metrics.mean_absolute_error(outputs[test_index], scores)\n",
    "print('Final Mean Absolute Error:', score/5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
